{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda2b01f",
   "metadata": {},
   "source": [
    "# Data Exploration: Begin by exploring the dataset. What are the different topics/categories \n",
    "present in the dataset? What is the distribution of articles across these topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92740af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset: Index(['publish_date', 'headline_text'], dtype='object')\n",
      "\n",
      "Categories present in the dataset:\n",
      "[20030219 20030220 20030221 ... 20211229 20211230 20211231]\n",
      "\n",
      "Distribution of articles across topics:\n",
      "publish_date\n",
      "20120824    384\n",
      "20130412    383\n",
      "20110222    380\n",
      "20120814    379\n",
      "20130514    378\n",
      "           ... \n",
      "20210605      6\n",
      "20211023      5\n",
      "20210515      5\n",
      "20210806      1\n",
      "20170209      1\n",
      "Name: count, Length: 6882, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"/Users/anubhavshroti/Desktop/AI Solutions/NLP day 2 dataset abcnews-date-text.csv\"  # Replace with the actual path\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Data Exploration\n",
    "column_names = df.columns\n",
    "print(\"Column names in the dataset:\", column_names)\n",
    "\n",
    "# Assuming the first column contains the categories\n",
    "category_column = column_names[0]\n",
    "print(\"\\nCategories present in the dataset:\")\n",
    "print(df[category_column].unique())\n",
    "\n",
    "print(\"\\nDistribution of articles across topics:\")\n",
    "print(df[category_column].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58996c4d",
   "metadata": {},
   "source": [
    "# Bag-of-Words (BoW): Implement a Bag-of-Words (BoW) model using CountVectorizer \n",
    "or TF-IDF to transform the text data into numerical features. Discuss the advantages and \n",
    "limitations of BoW in this context. Apply both unigram and bigram techniques and \n",
    "compare their effects on classification accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84381cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for BoW (Unigram): 1.0000\n",
      "\n",
      "Accuracy for BoW (Bigram): 1.0000\n",
      "\n",
      "Accuracy for TF-IDF (Unigram): 1.0000\n",
      "\n",
      "Accuracy for TF-IDF (Bigram): 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"/Users/anubhavshroti/Desktop/AI Solutions/NLP day 2 dataset abcnews-date-text.csv\"  # Replace with the actual path\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Create a temporary 'category' column with a placeholder value for demonstration\n",
    "df['category'] = 'placeholder_category'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['headline_text'], df['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Bag-of-Words (BoW) with unigram\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_bow_unigram = vectorizer.fit_transform(X_train)\n",
    "X_test_bow_unigram = vectorizer.transform(X_test)\n",
    "\n",
    "# Bag-of-Words (BoW) with bigram\n",
    "vectorizer_bigram = CountVectorizer(ngram_range=(2, 2))\n",
    "X_train_bow_bigram = vectorizer_bigram.fit_transform(X_train)\n",
    "X_test_bow_bigram = vectorizer_bigram.transform(X_test)\n",
    "\n",
    "# TF-IDF with unigram\n",
    "tfidf_vectorizer_unigram = TfidfVectorizer()\n",
    "X_train_tfidf_unigram = tfidf_vectorizer_unigram.fit_transform(X_train)\n",
    "X_test_tfidf_unigram = tfidf_vectorizer_unigram.transform(X_test)\n",
    "\n",
    "# TF-IDF with bigram\n",
    "tfidf_vectorizer_bigram = TfidfVectorizer(ngram_range=(2, 2))\n",
    "X_train_tfidf_bigram = tfidf_vectorizer_bigram.fit_transform(X_train)\n",
    "X_test_tfidf_bigram = tfidf_vectorizer_bigram.transform(X_test)\n",
    "\n",
    "# Classification using Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Function to train and evaluate the classifier\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, vectorizer_type):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nAccuracy for {vectorizer_type}: {acc:.4f}\")\n",
    "\n",
    "# Evaluate unigram BoW\n",
    "train_and_evaluate(X_train_bow_unigram, X_test_bow_unigram, y_train, y_test, \"BoW (Unigram)\")\n",
    "\n",
    "# Evaluate bigram BoW\n",
    "train_and_evaluate(X_train_bow_bigram, X_test_bow_bigram, y_train, y_test, \"BoW (Bigram)\")\n",
    "\n",
    "# Evaluate unigram TF-IDF\n",
    "train_and_evaluate(X_train_tfidf_unigram, X_test_tfidf_unigram, y_train, y_test, \"TF-IDF (Unigram)\")\n",
    "\n",
    "# Evaluate bigram TF-IDF\n",
    "train_and_evaluate(X_train_tfidf_bigram, X_test_tfidf_bigram, y_train, y_test, \"TF-IDF (Bigram)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f0b65",
   "metadata": {},
   "source": [
    "# N-grams: Explore the use of N-grams (bi-grams, tri-grams) in feature engineering. How do \n",
    "different N-gram ranges impact the performance of the classification model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08398491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for (1, 1)-gram: 1.0000\n",
      "\n",
      "Accuracy for (2, 2)-gram: 1.0000\n",
      "\n",
      "Accuracy for (3, 3)-gram: 1.0000\n",
      "\n",
      "Accuracy for (1, 3)-gram: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"/Users/anubhavshroti/Desktop/AI Solutions/NLP day 2 dataset abcnews-date-text.csv\"  # Replace with the actual path\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Create a temporary 'category' column with a placeholder value for demonstration\n",
    "df['category'] = 'placeholder_category'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['headline_text'], df['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to train and evaluate the classifier with different N-gram ranges\n",
    "def train_and_evaluate_ngram(X_train, X_test, y_train, y_test, ngram_range):\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "    X_train_ngram = vectorizer.fit_transform(X_train)\n",
    "    X_test_ngram = vectorizer.transform(X_test)\n",
    "\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train_ngram, y_train)\n",
    "    y_pred = clf.predict(X_test_ngram)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nAccuracy for {ngram_range}-gram: {acc:.4f}\")\n",
    "\n",
    "# Evaluate unigram\n",
    "train_and_evaluate_ngram(X_train, X_test, y_train, y_test, (1, 1))\n",
    "\n",
    "# Evaluate bigram\n",
    "train_and_evaluate_ngram(X_train, X_test, y_train, y_test, (2, 2))\n",
    "\n",
    "# Evaluate trigram\n",
    "train_and_evaluate_ngram(X_train, X_test, y_train, y_test, (3, 3))\n",
    "\n",
    "# Evaluate a combination of unigram, bigram, and trigram\n",
    "train_and_evaluate_ngram(X_train, X_test, y_train, y_test, (1, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b731d0a",
   "metadata": {},
   "source": [
    "# TF-IDF: Apply TF-IDF (Term Frequency-Inverse Document Frequency) to the text data. \n",
    "Describe how TF-IDF works and its significance in capturing the importance of words \n",
    "across documents. Compare the results of TF-IDF with the BoW approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19220ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for TF-IDF: 1.0000\n",
      "\n",
      "Accuracy for Bag-of-Words: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"/Users/anubhavshroti/Desktop/AI Solutions/NLP day 2 dataset abcnews-date-text.csv\"  # Replace with the actual path\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Create a temporary 'category' column with a placeholder value for demonstration\n",
    "df['category'] = 'placeholder_category'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['headline_text'], df['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Bag-of-Words (BoW)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# Classification using Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Function to train and evaluate the classifier\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, vectorizer_type):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nAccuracy for {vectorizer_type}: {acc:.4f}\")\n",
    "\n",
    "# Evaluate TF-IDF\n",
    "train_and_evaluate(X_train_tfidf, X_test_tfidf, y_train, y_test, \"TF-IDF\")\n",
    "\n",
    "# Evaluate Bag-of-Words\n",
    "train_and_evaluate(X_train_bow, X_test_bow, y_train, y_test, \"Bag-of-Words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72862940",
   "metadata": {},
   "source": [
    "# One-Hot Encoding: Investigate the application of One-Hot Encoding to encode categorical \n",
    "variables or labels. Can One-Hot Encoding be used directly for text classification? Why or \n",
    "why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5be951e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for TF-IDF: 1.0000\n",
      "\n",
      "Accuracy for Bag-of-Words: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = \"/Users/anubhavshroti/Desktop/AI Solutions/NLP day 2 dataset abcnews-date-text.csv\"  # Replace with the actual path\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Create a temporary 'category' column with a placeholder value for demonstration\n",
    "df['category'] = 'placeholder_category'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['headline_text'], df['category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Bag-of-Words (BoW)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# Classification using Naive Bayes\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Function to train and evaluate the classifier\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, vectorizer_type):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nAccuracy for {vectorizer_type}: {acc:.4f}\")\n",
    "\n",
    "# Evaluate TF-IDF\n",
    "train_and_evaluate(X_train_tfidf, X_test_tfidf, y_train, y_test, \"TF-IDF\")\n",
    "\n",
    "# Evaluate Bag-of-Words\n",
    "train_and_evaluate(X_train_bow, X_test_bow, y_train, y_test, \"Bag-of-Words\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523e3577",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
