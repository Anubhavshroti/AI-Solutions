{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "38f781e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Image Shape: (213, 320, 3)\n",
      "Reshaped Image Shape: (1, 224, 224, 3)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "=================================================================\n",
      "Total params: 0 (0.00 Byte)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m train_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m, shear_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     42\u001b[0m test_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Anaconda/anaconda3/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1649\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1564\u001b[0m     directory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1579\u001b[0m ):\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m \n\u001b[1;32m   1582\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;124;03m        and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[1;32m   1648\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DirectoryIterator(\n\u001b[1;32m   1650\u001b[0m         directory,\n\u001b[1;32m   1651\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1652\u001b[0m         target_size\u001b[38;5;241m=\u001b[39mtarget_size,\n\u001b[1;32m   1653\u001b[0m         color_mode\u001b[38;5;241m=\u001b[39mcolor_mode,\n\u001b[1;32m   1654\u001b[0m         keep_aspect_ratio\u001b[38;5;241m=\u001b[39mkeep_aspect_ratio,\n\u001b[1;32m   1655\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[1;32m   1656\u001b[0m         class_mode\u001b[38;5;241m=\u001b[39mclass_mode,\n\u001b[1;32m   1657\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format,\n\u001b[1;32m   1658\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1659\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m   1660\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[1;32m   1661\u001b[0m         save_to_dir\u001b[38;5;241m=\u001b[39msave_to_dir,\n\u001b[1;32m   1662\u001b[0m         save_prefix\u001b[38;5;241m=\u001b[39msave_prefix,\n\u001b[1;32m   1663\u001b[0m         save_format\u001b[38;5;241m=\u001b[39msave_format,\n\u001b[1;32m   1664\u001b[0m         follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[1;32m   1665\u001b[0m         subset\u001b[38;5;241m=\u001b[39msubset,\n\u001b[1;32m   1666\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[1;32m   1667\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m   1668\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Anaconda/anaconda3/lib/python3.11/site-packages/keras/src/preprocessing/image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m    562\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    565\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "# Load the image\n",
    "img_path = '_happy_jumping_on_beach-40815.jpg'\n",
    "img = load_img(img_path)\n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "img_array = img_to_array(img)\n",
    "\n",
    "# Check the shape of the original image array\n",
    "print(\"Original Image Shape:\", img_array.shape)\n",
    "\n",
    "# Rescale the image array to fit the model's input shape\n",
    "img_array = tf.image.resize(img_array, (224, 224))  # Resize the image to (224, 224)\n",
    "img_array = tf.reshape(img_array, (1, 224, 224, 3))\n",
    "\n",
    "# Check the shape after resizing\n",
    "print(\"Reshaped Image Shape:\", img_array.shape)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define your CNN model\n",
    "model = models.Sequential()\n",
    "# ... (rest of your model definition)\n",
    "\n",
    "# Build the model\n",
    "model.build(input_shape=(1, 224, 224, 3))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model architecture\n",
    "model.summary()\n",
    "\n",
    "# Load your data and preprocess it (adjust as needed based on your data)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('train.csv', target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory('test.csv', target_size=(224, 224), batch_size=32, class_mode='binary')\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=10, validation_data=validation_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df43920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eda863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2426edbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76000bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9c5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf47f46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b00f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1de5018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/938], Loss: 0.1213\n",
      "Epoch [1/5], Step [200/938], Loss: 0.4268\n",
      "Epoch [1/5], Step [300/938], Loss: 0.0464\n",
      "Epoch [1/5], Step [400/938], Loss: 0.0628\n",
      "Epoch [1/5], Step [500/938], Loss: 0.1444\n",
      "Epoch [1/5], Step [600/938], Loss: 0.0309\n",
      "Epoch [1/5], Step [700/938], Loss: 0.0550\n",
      "Epoch [1/5], Step [800/938], Loss: 0.0466\n",
      "Epoch [1/5], Step [900/938], Loss: 0.0886\n",
      "Epoch [2/5], Step [100/938], Loss: 0.0260\n",
      "Epoch [2/5], Step [200/938], Loss: 0.0370\n",
      "Epoch [2/5], Step [300/938], Loss: 0.0264\n",
      "Epoch [2/5], Step [400/938], Loss: 0.0091\n",
      "Epoch [2/5], Step [500/938], Loss: 0.0303\n",
      "Epoch [2/5], Step [600/938], Loss: 0.0157\n",
      "Epoch [2/5], Step [700/938], Loss: 0.0493\n",
      "Epoch [2/5], Step [800/938], Loss: 0.0671\n",
      "Epoch [2/5], Step [900/938], Loss: 0.0034\n",
      "Epoch [3/5], Step [100/938], Loss: 0.0240\n",
      "Epoch [3/5], Step [200/938], Loss: 0.0285\n",
      "Epoch [3/5], Step [300/938], Loss: 0.0451\n",
      "Epoch [3/5], Step [400/938], Loss: 0.0293\n",
      "Epoch [3/5], Step [500/938], Loss: 0.0093\n",
      "Epoch [3/5], Step [600/938], Loss: 0.0327\n",
      "Epoch [3/5], Step [700/938], Loss: 0.0359\n",
      "Epoch [3/5], Step [800/938], Loss: 0.0049\n",
      "Epoch [3/5], Step [900/938], Loss: 0.0024\n",
      "Epoch [4/5], Step [100/938], Loss: 0.0096\n",
      "Epoch [4/5], Step [200/938], Loss: 0.0021\n",
      "Epoch [4/5], Step [300/938], Loss: 0.0014\n",
      "Epoch [4/5], Step [400/938], Loss: 0.0130\n",
      "Epoch [4/5], Step [500/938], Loss: 0.0046\n",
      "Epoch [4/5], Step [600/938], Loss: 0.0259\n",
      "Epoch [4/5], Step [700/938], Loss: 0.0046\n",
      "Epoch [4/5], Step [800/938], Loss: 0.0008\n",
      "Epoch [4/5], Step [900/938], Loss: 0.0040\n",
      "Epoch [5/5], Step [100/938], Loss: 0.0259\n",
      "Epoch [5/5], Step [200/938], Loss: 0.0494\n",
      "Epoch [5/5], Step [300/938], Loss: 0.0089\n",
      "Epoch [5/5], Step [400/938], Loss: 0.0012\n",
      "Epoch [5/5], Step [500/938], Loss: 0.0043\n",
      "Epoch [5/5], Step [600/938], Loss: 0.0280\n",
      "Epoch [5/5], Step [700/938], Loss: 0.0256\n",
      "Epoch [5/5], Step [800/938], Loss: 0.0020\n",
      "Epoch [5/5], Step [900/938], Loss: 0.0381\n",
      "Test Accuracy: 99.06%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F  # Add this import for F.relu\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):  # Fix the method name\n",
    "        super(SimpleCNN, self).__init__()  # Fix the super() call\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# ... rest of your code ...\n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SimpleCNN(num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Testing the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f844e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
